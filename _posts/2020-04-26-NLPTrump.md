---
title: "Natural Language Processing: Trump Speeches"
date: 2020-04-10
tags: [NLP]
excerpt: "Basic NLP on Trump's speeches"
classes: wide
---

## Import modules


```python
import pickle
import pandas as pd
import re
import string
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from textblob import TextBlob
import seaborn as sns
from gensim import matutils, models
import scipy.sparse
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction import text

lemmatizer = WordNetLemmatizer()
```


```python
# Pickling the dataset with the web scraped data

database = pickle.load(open('df_clean', 'rb'))
```


```python
database
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>titles</th>
      <th>dates</th>
      <th>transcripts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 20, 2020</td>
      <td>Donald Trump: (01:12) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Donald Trump &amp; Coronavirus Task Force Press Co...</td>
      <td>Mar 26, 2020</td>
      <td>Donald Trump: (00:15) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 19, 2020</td>
      <td>Donald Trump: (00:01) Thank you very much. I’d...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 18, 2020</td>
      <td>Donald Trump: (02:13) Thank you very much. Goo...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 17, 2020</td>
      <td>Donald Trump: (02:30) Thank you. Thank you ver...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 16, 2020</td>
      <td>Donald Trump: (03:19) Thank you very much. Our...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Donald Trump Coronavirus Press Briefing Transc...</td>
      <td>Apr 15, 2020</td>
      <td>Donald Trump: (00:09) Okay. Thank you very muc...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Donald Trump Coronavirus Press Briefing Transc...</td>
      <td>Apr 14, 2020</td>
      <td>Donald Trump: (00:03) Very importantly, I’d li...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 13, 2020</td>
      <td>Donald Trump: (11:23) Thank you very much, eve...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Apr 21, 2020</td>
      <td>Donald Trump: (03:04) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Donald Trump Coronavirus Update Transcript Feb...</td>
      <td>Feb 29, 2020</td>
      <td>Donald Trump: (00:00) Thank you very much, eve...</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Donald Trump, Mike Pence, and Coronavirus Task...</td>
      <td>Mar 9, 2020</td>
      <td>Donald Trump: (03:01) Thank you very much. We ...</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Donald Trump Speech Transcript on Coronavirus,...</td>
      <td>Mar 11, 2020</td>
      <td>President Trump: (00:00) My fellow Americans, ...</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Donald Trump Speech Transcript: Declares Coron...</td>
      <td>Mar 13, 2020</td>
      <td>Donald Trump: (00:00) To unleash the full powe...</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Donald Trump Coronavirus Press Conference Tran...</td>
      <td>Mar 14, 2020</td>
      <td>Donald Trump: (00:19) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Donald Trump and Coronavirus Task Force News C...</td>
      <td>Mar 15, 2020</td>
      <td>Donald Trump: (00:06) Beautiful day outside. A...</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Donald Trump Coronavirus Task Force Update: Ma...</td>
      <td>Mar 16, 2020</td>
      <td>Donald Trump: (09:24) I’m glad to see that you...</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Coronavirus Task Force Briefing Transcript Mar...</td>
      <td>Mar 17, 2020</td>
      <td>Donald Trump: (18:28) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Donald Trump and Coronavirus Task Force News B...</td>
      <td>Mar 18, 2020</td>
      <td>Donald Trump: (19:18) Thank you very much. I w...</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 19, 2020</td>
      <td>Donald Trump: (01:51) Thank you very much. I t...</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Donald Trump &amp; Coronavirus Task Force March 20...</td>
      <td>Mar 20, 2020</td>
      <td>Donald Trump: (04:25) Thank you very much. I h...</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Donald Trump Coronavirus Task Force Update Tra...</td>
      <td>Mar 21, 2020</td>
      <td>Donald Trump: (01:22) Thank you very much. A l...</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 22, 2020</td>
      <td>Donald Trump: (00:56) Thank you very much. Jus...</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 23, 2020</td>
      <td>Donald Trump: (00:00) Well, thank you very muc...</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 24, 2020</td>
      <td>President Trump: (00:10) Thank you very much. ...</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Donald Trump Coronavirus Task Force Press Conf...</td>
      <td>Mar 25, 2020</td>
      <td>Donald Trump: (00:00) Thank you very much. So,...</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Donald Trump &amp; Coronavirus Task Force Press Co...</td>
      <td>Mar 26, 2020</td>
      <td>Donald Trump: (00:15) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 27, 2020</td>
      <td>Donald Trump: (01:03) Thank you very much. Gre...</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 29, 2020</td>
      <td>Donald Trump: (01:35) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Donald Trump Coronavirus Task Force Press Conf...</td>
      <td>Mar 30, 2020</td>
      <td>Donald Trump: (00:00) Appreciate you being her...</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Mar 31, 2020</td>
      <td>Donald Trump: (01:36) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Apr 1, 2020</td>
      <td>Donald Trump: (00:05) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Donald Trump Coronavirus Task Force Briefing A...</td>
      <td>Apr 2, 2020</td>
      <td>Donald Trump: (01:08) Okay. Thank you very muc...</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Donald Trump Coronavirus Briefing Transcript A...</td>
      <td>Apr 3, 2020</td>
      <td>Donald Trump: (00:00) With Kevin McCarthy, fut...</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Donald Trump Coronavirus Task Force Transcript...</td>
      <td>Apr 4, 2020</td>
      <td>Donald Trump: (01:08) Thank you very much. Bus...</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Apr 5, 2020</td>
      <td>Donald Trump: (04:25) Okay. Thank you very muc...</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Apr 6, 2020</td>
      <td>Donald Trump: (03:41) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Donald Trump Coronavirus Task Force Briefing A...</td>
      <td>Apr 7, 2020</td>
      <td>Donald Trump: (00:05) Thank you very much. Don...</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Donald Trump Coronavirus Task Force Briefing T...</td>
      <td>Apr 8, 2020</td>
      <td>Donald Trump: (00:31) Thank you very much. Tha...</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Donald Trump Coronavirus Task Force Briefing A...</td>
      <td>Apr 9, 2020</td>
      <td>Donald Trump: (00:13) Thank you very much ever...</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Donald Trump Coronavirus Task Force Press Conf...</td>
      <td>Apr 10, 2020</td>
      <td>Donald Trump: (00:24) Thank you very much ever...</td>
    </tr>
  </tbody>
</table>
</div>



First, let's change the dates to a datetime format to be able to work with it.


```python
database.dates = pd.to_datetime(database.dates, format = '%b %d, %Y')
```

Each time Donald Trump speaks, it is referenced in the transcripts as "Donald Trump:" or "President Trump:". Since we get rid of all the other intervenants and everything in the transcripts is from Donald Trump, we will remove these labels. Moreover, each label goes with a "time tag" that we will remove too.


```python
def clean_text_round1(text):

    text = re.sub(r'Donald Trump:', '', text)
    text = re.sub(r'President Trump:', '', text)
    text = re.sub(r'\(\d+:\d+:*\d*\)', '', text)

    return text
```


```python
database.transcripts = database.transcripts.apply(clean_text_round1)
```


```python
pickle.dump(database, open('df_clean_round1', 'wb'))
```


In the second round of cleaning, we proceed to more common cleaning tasks: lowercase the text, remove punctuation, numbers, words containing numbers and text in square brackets.


```python
def clean_text_round2(text):

    text = text.lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text
```


```python
database.transcripts = database.transcripts.apply(clean_text_round2)
```

## Exploration Data Analysis

### Wordcloud


```python
# Creating a list of words to exclude since they do not convey any information
add_stop_words = ['ll', 've', 'lot', 'don']
stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)
```


```python
# Making a big 'body text' out of all the transcripts

corpus = database.transcripts.values
corpus = ''.join(corpus)
```


```python
wc = WordCloud(stopwords=stop_words, background_color="white", colormap="Dark2",
               max_font_size=130)

wc.generate(corpus)
plt.figure(figsize = (14,6))
plt.axis('off')
plt.imshow(wc, interpolation="bilinear")
plt.show()
```


![png](/images/Naturalprocessinglanguage_files/Naturalprocessinglanguage_19_0.png)


Let's see what we can discover:
* Trump uses a lot of generic/vague vocabulary: people, big, okay, way...
* Positive words: good, great, right.
* Surprisingly, virus vocabulary not often used.

### Wordcloud with only nouns

The function, here below, returns a corpus containing only the nouns of the transcripts of the speeches of Donald Trump. Then, we will generate a wordcloud with this corpus.


```python
# Let's create a function to pull out nouns from a string of text
from nltk import word_tokenize, pos_tag

def nouns(text):
    '''Given a string of text, tokenize the text and pull out only the nouns.'''
    is_noun = lambda pos: pos[:2] == 'NN'
    tokenized = word_tokenize(text)
    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]
    return ' '.join(all_nouns)
```


```python
nouns= nouns(corpus)
```


```python
wc = WordCloud(stopwords=stop_words, background_color="white", colormap="Dark2",
               max_font_size=130)

wc.generate(nouns)
plt.figure(figsize = (14,6))
plt.axis('off')
plt.imshow(wc, interpolation="bilinear")
plt.show()
```


![png](/images/Naturalprocessinglanguage_files/Naturalprocessinglanguage_25_0.png)


Some medical vocabulary appears when we look only at the nouns: Ventilator, hospital, virus, doctor...

### Wordcloud with only nouns

Similarly to the 'nouns' function, 'adjective' returns a corpus containing only the adjectives of the transcripts of the speeches of Donald Trump.


```python
def adjective(text):
    '''Given a string of text, tokenize the text and pull out only the nouns.'''
    is_noun = lambda pos: pos[:2] == 'JJ'
    tokenized = word_tokenize(text)
    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)]
    return ' '.join(all_nouns)
```


```python
adjectives = adjective(corpus)
```


```python
wc = WordCloud(stopwords=stop_words, background_color="white", colormap="Dark2",
               max_font_size=130)

wc.generate(adjectives)
plt.figure(figsize = (14,6))
plt.axis('off')
plt.imshow(wc, interpolation="bilinear")
plt.show()
```


![png](/images/Naturalprocessinglanguage_files/Naturalprocessinglanguage_31_0.png)


In these time of crisis, Trump makes extensive usage of positive adjectives: great, good, incredible, beautiful, fantastic... Positive adjectives dominate the negative ones. Still, some negative adjective appear: though, hard, bad.

## Sentiment analysis

In this section, we will use TextBlob to estimate the polarity and the subjectivity of each speech. Subjectivity scores subjectivity within the range [0,1]. Polarity measures positiveness/negativeness, -1 means negative statement and 1 means positive statement.


```python
# Example positive statement:
sentence_pos = "This jacuzzi is great, I love it"
TextBlob(sentence_pos).sentiment
```




    Sentiment(polarity=0.65, subjectivity=0.675)




```python
# Example positive statement:
sentence_pos = "The food was awful, let's get out of here"
TextBlob(sentence_pos).sentiment
```




    Sentiment(polarity=-1.0, subjectivity=1.0)



Let's apply TextBlob on the transcripts.


```python
pol = lambda x: TextBlob(x).sentiment.polarity
sub = lambda x: TextBlob(x).sentiment.subjectivity

database['polarity'] = database['transcripts'].apply(pol)
database['subjectivity'] = database['transcripts'].apply(sub)
```


```python
plt.figure(figsize=(14,6))
sns.lineplot(x = 'dates', y = 'polarity', data = database)
plt.ylim((-1,1))
plt.show()
```


![png](/images/Naturalprocessinglanguage_files/Naturalprocessinglanguage_39_0.png)



```python
plt.figure(figsize=(14,6))
sns.lineplot(x = 'dates', y = 'subjectivity', data = database)
plt.ylim((0,1))
plt.show()
```


![png](/images/Naturalprocessinglanguage_files/Naturalprocessinglanguage_40_0.png)



```python
print("The average subjectivity score accross all the speeches is: {:.3f}".format(database.subjectivity.mean()))
```

    The average subjectivity score accross all the speeches is: 0.515



```python
print("The average subjectivity score accross all the speeches is: {:.3f}".format(database.polarity.mean()))
```

    The average subjectivity score accross all the speeches is: 0.189


Although it was worth the try, we do not learn much from this sentiment analysis using TextBlob. Subjectivity and polarity do not vary much with the time of the speech. Overall, the speeches of Trump are rather positive.

## Topic Modelling

To end this project, topic modelling will be applied. Indeed, we will:

1. Create a function that returns a corpus containing only the nouns and the adjectives of the initial input corpus.

2. Create a new document-term matrix using only nouns and adjectives. The parameter 'max_df' is used for removing data values that appear too frequently, also known as "corpus-specific stop words". For example: max_df = 0.50 means "It ignores terms that appear in more than 50% of the documents".

3. Latent Dirichlet Allocation requires specific corpus and vocabulary dictionary to work.



```python
# Create function

def nouns_adj(text):
    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'
    tokenized = word_tokenize(text)
    coucou = [lemmatizer.lemmatize(x) for x in tokenized]
    nouns_adj = [word for (word, pos) in pos_tag(coucou) if is_noun_adj(pos)]
    return ' '.join(nouns_adj)

data_nouns_adj = pd.DataFrame(database.transcripts.apply(nouns_adj))
```


```python
# Create a new document-term matrix using only nouns and adjectives

cvna = CountVectorizer(stop_words=stop_words, max_df = 0.7)
data_cvna = cvna.fit_transform(data_nouns_adj.transcripts)
data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())
data_dtmna.index = data_nouns_adj.index
```


```python
# Create the gensim corpus
corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))

# Create the vocabulary dictionary
id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())
```


```python
# Let's start with 2 topics
ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=150, alpha = 'auto')
ldana.print_topics()
```




    [(0,
      '0.006*"decision" + 0.003*"horrible" + 0.003*"drug" + 0.003*"market" + 0.003*"action" + 0.003*"trade" + 0.003*"bed" + 0.003*"stock" + 0.003*"answer" + 0.003*"bank"'),
     (1,
      '0.005*"military" + 0.004*"decision" + 0.004*"person" + 0.004*"jersey" + 0.004*"john" + 0.003*"dr" + 0.003*"bed" + 0.003*"oil" + 0.003*"center" + 0.003*"stockpile"')]




```python
# Let's try 3 topics
ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=150)
ldana.print_topics()
```




    [(0,
      '0.006*"decision" + 0.005*"drug" + 0.005*"person" + 0.005*"military" + 0.004*"bed" + 0.004*"oil" + 0.003*"answer" + 0.003*"vaccine" + 0.003*"center" + 0.003*"jersey"'),
     (1,
      '0.006*"airline" + 0.005*"decision" + 0.005*"hand" + 0.004*"meeting" + 0.004*"fault" + 0.004*"john" + 0.004*"step" + 0.004*"bank" + 0.003*"loan" + 0.003*"tony"'),
     (2,
      '0.004*"military" + 0.004*"bed" + 0.004*"horrible" + 0.004*"capacity" + 0.003*"dr" + 0.003*"heard" + 0.003*"stockpile" + 0.003*"treatment" + 0.003*"therapy" + 0.003*"trade"')]




```python
# Let's try 4 topics
ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=150, per_word_topics=True)
ldana.print_topics()
```




    [(0,
      '0.007*"decision" + 0.005*"bed" + 0.004*"trade" + 0.004*"person" + 0.004*"military" + 0.003*"john" + 0.003*"news" + 0.003*"oil" + 0.003*"short" + 0.003*"mexico"'),
     (1,
      '0.006*"organization" + 0.005*"ceo" + 0.005*"bank" + 0.004*"judge" + 0.004*"food" + 0.003*"election" + 0.003*"date" + 0.003*"john" + 0.003*"program" + 0.003*"memo"'),
     (2,
      '0.005*"military" + 0.004*"decision" + 0.004*"airline" + 0.004*"jersey" + 0.004*"order" + 0.003*"person" + 0.003*"oil" + 0.003*"stock" + 0.003*"center" + 0.003*"vaccine"'),
     (3,
      '0.005*"restaurant" + 0.004*"decision" + 0.004*"drug" + 0.004*"terrible" + 0.004*"answer" + 0.004*"military" + 0.004*"horrible" + 0.004*"act" + 0.003*"heard" + 0.003*"dr"')]



Based on these results, we can try to infer the topics discussed by Trump. For example for the 3 topics lda, the 3 inferred topics are:

* Medical related: drug, vaccine, center.

* economy related: airline, bank, loan.

* healthcare related: bed, capacity, treatment, therapy, stockpile.

### Sources

<a href="https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL">Youtube playlist of Sentdex on nltk module</a>

<a href="https://www.youtube.com/results?search_query=natural+language+processing+python">YPyOhio video on Natural Language Processing</a>
